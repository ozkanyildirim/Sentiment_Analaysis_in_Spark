{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "colab": {
      "name": "ESPRIT_sentiment_analysis_pyspark.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7Vld5BTZg6p"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPxbbRL6ZdHB"
      },
      "source": [
        "# Sentiment Analaysis ESPRIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIyEXymmaXuL"
      },
      "source": [
        "## Part-1: Initials (Preparing Train and Test Data **Frames**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tum--aDgbeec"
      },
      "source": [
        "> ### I.  Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG_3zMIOY26q"
      },
      "source": [
        "# general purpose modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# pyspark modules\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# spark nlp modules\n",
        "import sparknlp\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sCpNPlvd5oB"
      },
      "source": [
        "> ### II.  Starting a Pyspark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6b2M980tsod"
      },
      "source": [
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNvEeZwnekzL"
      },
      "source": [
        "> ### III.  Retrieving Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt0eWvZCY26t"
      },
      "source": [
        "comments_train = spark.read.options(delimiter=';').csv('train data product reviews.csv', inferSchema=True, header=True)\n",
        "comments_train.show(truncate=True, n=5)\n",
        "comments_train.count(), comments_train.select('label').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Zxwf2RY26u"
      },
      "source": [
        "In 'label' column we have 0's and 1's only. Let's rearrange this data frame as *df_train*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmJ8jkfMY26v"
      },
      "source": [
        "df_train = comments_train.select('text', 'label')\n",
        "df_train.show(truncate=True, n=5)\n",
        "df_test.groupBy('label').count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP2qC4ibVZcC"
      },
      "source": [
        "df_train.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvTS15kIKCUH"
      },
      "source": [
        "def balance_check(df, col='label'):\n",
        "  \"\"\"\n",
        "  Checks the balance of data regarding labels and displays.\n",
        "  df: data frame\n",
        "  col: string column\n",
        "  \"\"\"\n",
        "  positive = df.where(df.label == '1').count()\n",
        "  negative = df.where(df.label == '0').count()\n",
        "  pos_percent = 100 * positive/(positive + negative)\n",
        "  neg_percent = 100 * negative/(positive + negative)\n",
        "  print(f'Positive Comments: {positive} which is %{pos_percent}')\n",
        "  print(f'Negative Comments: {negative} which is %{neg_percent}')\n",
        "\n",
        "balance_check(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plvshF7MNQNF"
      },
      "source": [
        "Given the distribution of the comments in training data we have a relative unbalanced data (~ 0.28 - 0.72). Before deciding whether applying a downsizing or upsizing technique, let's first check whether do we have duplications in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFnyj8TbSJDc"
      },
      "source": [
        "import pyspark.sql.functions as funcs\n",
        "df_train.groupBy(df_train.text)\\\n",
        "    .count()\\\n",
        "    .where(funcs.col('count') > 1)\\\n",
        "    .select(funcs.sum('count'))\\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE5Wbe1PWdjP"
      },
      "source": [
        "Let's drop the duplicated rows and keep only the first occurences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36o3jDvKW2G7"
      },
      "source": [
        "df_train = df_train.dropDuplicates((['text']))\n",
        "balance_check(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFlN0d8OXTYi"
      },
      "source": [
        "After removing the duplications, the distribution of comments in the training data changed slightly to the positive (more balanced ~ 0.33 - 0.67). For now, we keep the data in this distribution and do not apply any downsizing or upsizing technique (or generation), but we use the F1 score as a performance metric to avoid being biased by the data distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI3aj_VWY26w"
      },
      "source": [
        "Now we are going to maintain a *df_test* similar to *df_train*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJryBbfzY26w"
      },
      "source": [
        "comments_test = spark.read.options(delimiter=';').csv('test data product reviews.csv', inferSchema=True, header=True)\n",
        "comments_test.show(truncate=True, n=5)\n",
        "comments_test.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5YN-XmqY26x"
      },
      "source": [
        "We are going to use *regex* to describe patters to obtain a clean data frame with columns text and label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAQtHWMeY26y"
      },
      "source": [
        "regex_pattern = r'\"*([01])(.+)'\n",
        "comments_test = comments_test.withColumn('text', regexp_extract(col('label,text'), regex_pattern, 2))\\\n",
        "                 .withColumn('label', regexp_extract(col('label,text'), regex_pattern, 1))\n",
        "df_test = comments_test.select('text', 'label')\n",
        "df_test.show(truncate=True, n=5)\n",
        "df_test.count(), df_test.select('label').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN_lvDlaYxfk"
      },
      "source": [
        "import pyspark.sql.functions as funcs\n",
        "df_test.groupBy(df_test.text)\\\n",
        "    .count()\\\n",
        "    .where(funcs.col('count') > 1)\\\n",
        "    .select(funcs.sum('count'))\\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgIqCGX6ZC29"
      },
      "source": [
        "balance_check(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGx69lH8Yzln"
      },
      "source": [
        "Apperently we do not have duplications in test data. And our test data is balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQbwxIa6Y260"
      },
      "source": [
        "Now that we have both *df_train* and *df_test* in our targetted composition, we can progress with the **sentiment analysis**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ncjC1PZ9zw"
      },
      "source": [
        "## Part-2: Spark NLP Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpSJgnqxkt4t"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToEYKcCQmSz7"
      },
      "source": [
        "> ### I.  Logistic Regression and Naive Bayes with CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqTwqa-_jdb8"
      },
      "source": [
        ">> i. Building Pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnsGnbzfmeNm"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt\n",
        "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKHyFGc-m2Eb"
      },
      "source": [
        "%%time\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "      .setInputCols(\"document\")\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "    \n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "      \n",
        "normalizer = Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "stemmer = Stemmer()\\\n",
        "      .setInputCols([\"cleanTokens\"])\\\n",
        "      .setOutputCol(\"stem\")\n",
        "\n",
        "finisher = Finisher()\\\n",
        "      .setInputCols([\"stem\"])\\\n",
        "      .setOutputCols([\"token_features\"])\\\n",
        "      .setOutputAsArray(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "label_strIdx = StringIndexer(inputCol='label', outputCol='target')\n",
        "logReg = LogisticRegression(maxIter=5, regParam=0.01)\n",
        "naiveBayes = NaiveBayes(smoothing=150)\n",
        "countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"features\", vocabSize=10000, minDF=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rX-T4nVlG4W"
      },
      "source": [
        ">> ii. Forming Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0nXg0QYu3aC"
      },
      "source": [
        "# Pipeline for Logistic Regression with CountVectorizer\n",
        "nlp_pipeline_cv_lr = Pipeline(\n",
        "    stages=[document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            countVectors,\n",
        "            logReg\n",
        "            ])\n",
        "\n",
        "# Pipeline for Naive Bayes with CountVectorizer\n",
        "nlp_pipeline_cv_nb = Pipeline(\n",
        "    stages=[document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            countVectors,\n",
        "            naiveBayes\n",
        "            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kh_CEDLfvzh"
      },
      "source": [
        "\n",
        ">> iii. Logistic Regression with CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o17HwXsece77"
      },
      "source": [
        ">>> a. Applying LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSPb0mYKhpZm"
      },
      "source": [
        "modelLR = nlp_pipeline_cv_lr.fit(df_train)\n",
        "pred_lr = modelLR.transform(df_test)\n",
        "pred_lr = pred_lr.withColumn('label', pred_lr.label.cast(IntegerType()))\n",
        "pred_lr.filter(pred_lr['prediction'] == 0)\\\n",
        "    .select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
        "    .orderBy(\"probability\", ascending=False)\\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kDyh4huoBeN"
      },
      "source": [
        ">>> b. Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TyxypTfn51g"
      },
      "source": [
        "# Converting pred_lr to pandas data frame in order to using sklearn metrics library\n",
        "df_lr = pred_lr.select('text','label','prediction').toPandas()\n",
        "print(classification_report(df_lr.label, df_lr.prediction))\n",
        "print(accuracy_score(df_lr.label, df_lr.prediction))\n",
        "\n",
        "# Evaluation within the Spark Universe is also possible (for scaling issues)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol=\"prediction\")\n",
        "evaluator.evaluate(pred_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS3O0kMGhgeo"
      },
      "source": [
        "\n",
        ">> iv. Naive Bayes with CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RobQnAhgew"
      },
      "source": [
        ">>> a. Applying Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4txcr2rhgew"
      },
      "source": [
        "modelNB = nlp_pipeline_cv_nb.fit(df_train)\n",
        "pred_nb = modelNB.transform(df_test)\n",
        "pred_nb = pred_nb.withColumn('label', pred_nb.label.cast(IntegerType()))\n",
        "pred_nb.filter(pred_nb['prediction'] == 0)\\\n",
        "    .select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
        "    .orderBy(\"probability\", ascending=False)\\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TD2E-8Ihgex"
      },
      "source": [
        ">>> b. Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj3TcdCfhgey"
      },
      "source": [
        "# Converting pred_nb to pandas data frame in order to using sklearn metrics library\n",
        "df_nb = pred_nb.select('text','label','prediction').toPandas()\n",
        "print(classification_report(df_nb.label, df_nb.prediction))\n",
        "print(accuracy_score(df_nb.label, df_nb.prediction))\n",
        "\n",
        "# Evaluation within the Spark Universe is also possible (for scaling issues)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol=\"prediction\")\n",
        "evaluator.evaluate(pred_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOsHQIa9n5e0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Mxak03k6V8"
      },
      "source": [
        "> ### II.  TFIDF Logistic Regression and Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Q2y4Trk6WF"
      },
      "source": [
        ">> i. Building Pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPoz2Qa8k6WF"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeW-EpNrk6WG"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "      .setInputCols(\"document\")\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "\n",
        "stemmer = Stemmer()\\\n",
        "      .setInputCols([\"cleanTokens\"])\\\n",
        "      .setOutputCol(\"stem\")\n",
        "\n",
        "finisher = Finisher()\\\n",
        "      .setInputCols([\"stem\"])\\\n",
        "      .setOutputCols([\"token_features\"])\\\n",
        "      .setOutputAsArray(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
        "label_strIdx = StringIndexer(inputCol='label', outputCol='target')\n",
        "logReg = LogisticRegression(maxIter=5, regParam=0.01)\n",
        "naiveBayes = NaiveBayes(smoothing=140)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CclnoSPok6WG"
      },
      "source": [
        ">> ii. Forming Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iPeU0MVk6WG"
      },
      "source": [
        "# Pipeline for Logistic Regression with TFIDF\n",
        "nlp_pipeline_tf_lr = Pipeline(\n",
        "    stages=[document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            logReg\n",
        "            ])\n",
        "\n",
        "# Pipeline for Naive Bayes with TFIDF\n",
        "nlp_pipeline_tf_nb = Pipeline(\n",
        "    stages=[document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            naiveBayes\n",
        "            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhvxqkyZk6WH"
      },
      "source": [
        "\n",
        ">> iii. Logistic Regression with TFIDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvjdXiMYk6WI"
      },
      "source": [
        ">>> a. Applying LogReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a55rXBNBk6WJ"
      },
      "source": [
        "modelLR = nlp_pipeline_tf_lr.fit(df_train)\n",
        "pred_tf_lr = modelLR.transform(df_test)\n",
        "pred_tf_lr = pred_tf_lr.withColumn('label', pred_tf_lr.label.cast(IntegerType()))\n",
        "pred_tf_lr.filter(pred_tf_lr['prediction'] == 0)\\\n",
        "    .select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
        "    .orderBy(\"probability\", ascending=False)\\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5KgC2XOk6WJ"
      },
      "source": [
        ">>> b. Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bE8mBwFk6WK"
      },
      "source": [
        "# Converting pred_tf_lr to pandas data frame in order to using sklearn metrics library\n",
        "df_tf_lr = pred_tf_lr.select('text','label','prediction').toPandas()\n",
        "print(classification_report(df_tf_lr.label, df_tf_lr.prediction))\n",
        "print(accuracy_score(df_tf_lr.label, df_tf_lr.prediction))\n",
        "\n",
        "# Evaluation within the Spark Universe is also possible (for scaling issues)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol=\"prediction\")\n",
        "evaluator.evaluate(pred_tf_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EQI-djwk6WL"
      },
      "source": [
        "\n",
        ">> iv. Naive Bayes with CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MlycYByk6WL"
      },
      "source": [
        ">>> a. Applying Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj4Ixqv3k6WL"
      },
      "source": [
        "modelNB = nlp_pipeline_tf_nb.fit(df_train)\n",
        "pred_tf_nb = modelNB.transform(df_test)\n",
        "pred_tf_nb = pred_tf_nb.withColumn('label', pred_tf_nb.label.cast(IntegerType()))\n",
        "pred_tf_nb.filter(pred_tf_nb['prediction'] == 0)\\\n",
        "    .select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
        "    .orderBy(\"probability\", ascending=False)\\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDcGMIhAk6WM"
      },
      "source": [
        ">>> b. Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IztXIR9ok6WM"
      },
      "source": [
        "# Converting pred_tf_nb to pandas data frame in order to using sklearn metrics library\n",
        "df_tf_nb = pred_tf_nb.select('text','label','prediction').toPandas()\n",
        "print(classification_report(df_lr.label, df_lr.prediction))\n",
        "print(accuracy_score(df_lr.label, df_lr.prediction))\n",
        "\n",
        "# Evaluation within the Spark Universe is also possible (for scaling issues)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol=\"prediction\")\n",
        "evaluator.evaluate(pred_tf_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHF5j_euk6WM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYP7uotlmZxS"
      },
      "source": [
        "> ### IV. Logistic Regression with TFIDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pewKPGeVfw7F"
      },
      "source": [
        ">> i. Building Pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZO5By-lDSev"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtSu5nHHmxtd"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HpaC_FImy05"
      },
      "source": [
        "\n",
        "%%time\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "      \n",
        "normalizer = Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "stemmer = Stemmer()\\\n",
        "      .setInputCols([\"cleanTokens\"])\\\n",
        "      .setOutputCol(\"stem\")\n",
        "\n",
        "finisher = Finisher()\\\n",
        "      .setInputCols([\"stem\"])\\\n",
        "      .setOutputCols([\"token_features\"])\\\n",
        "      .setOutputAsArray(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
        "label_strIdx = StringIndexer(inputCol='label', outputCol='target')\n",
        "logReg = LogisticRegression(maxIter=5, regParam=0.01)\n",
        "\n",
        "nlp_pipeline_tf_lr = Pipeline(\n",
        "    stages=[document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemmatizer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            logReg\n",
        "            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37B8ZcuwUVjh"
      },
      "source": [
        "Please note that I also built pipelines with **Lemmatizer instead of Stemmer** and/or **without Normalizer**. Within all variants this annotator configuration performed best. Due to the readability of the code, I intentionally did not add any other pipeline variants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX733Hy5nYWx"
      },
      "source": [
        "nlp_pipeline_tf = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlT4cy8injl1"
      },
      "source": [
        "nlp_model_tf = nlp_pipeline_tf.fit(df_train)\n",
        "processed_tf_train = nlp_model_tf.transform(df_train)\n",
        "processed_tf_train.count()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNBM0ff5p-WN"
      },
      "source": [
        "nlp_model_tf = nlp_pipeline_tf.fit(df_train)\n",
        "processed_tf_test = nlp_model_tf.transform(df_test)\n",
        "processed_tf_test.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0p6tUElkOY7"
      },
      "source": [
        ">> ii. Applying Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhFOL9aHrq8H"
      },
      "source": [
        "lr = LogisticRegression(maxIter=5, regParam=0.01)\n",
        "\n",
        "lrModel = lr.fit(processed_tf_train)\n",
        "\n",
        "predictions_tf = lrModel.transform(processed_tf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y0p0FFglipf"
      },
      "source": [
        "predictions_tf.select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PAHa7KDmO4V"
      },
      "source": [
        "y_true = predictions_tf.select(\"label\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions_tf.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "print(classification_report(y_true.label, y_pred.prediction))\n",
        "print(accuracy_score(y_true.label, y_pred.prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO9sbrGfrrv3"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "\n",
        "evaluator.evaluate(predictions_tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDx1xt2cG0py"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A99TogfEIOJj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3FDlwnEIOW1"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "      .setInputCols(\"document\")\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "    \n",
        "\n",
        "finisher = Finisher()\\\n",
        "      .setInputCols([\"lemma\"])\\\n",
        "      .setOutputCols([\"token_features\"])\\\n",
        "      .setOutputAsArray(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
        "label_strIdx = StringIndexer(inputCol='label', outputCol='target')\n",
        "logReg = LogisticRegression(maxIter=5, regParam=0.01)\n",
        "\n",
        "nlp_pipeline_tf_lr = Pipeline(\n",
        "    stages=[document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemmatizer, \n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            label_strIdx,\n",
        "            logReg\n",
        "            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwvBXP19IOlB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmC6i6EgIOya"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2clWCaBUIPBS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n12mxX9LO-Sv"
      },
      "source": [
        "> ### V.  LogReg with Spark NLP Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLJZh09rO8m3"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "bert_embeddings = BertEmbeddings\\\n",
        "      .pretrained('bert_base_cased', 'en')\\\n",
        "      .setInputCols([\"document\",'cleanTokens'])\\\n",
        "      .setOutputCol(\"bert\")\\\n",
        "      .setCaseSensitive(False)\\\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings()\\\n",
        "      .setInputCols([\"document\", \"bert\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "    \n",
        "embeddings_finisher = EmbeddingsFinisher()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCols([\"finished_sentence_embeddings\"])\\\n",
        "      .setOutputAsVector(True)\\\n",
        "      .setCleanAnnotations(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6pVzIoTPELf"
      },
      "source": [
        "nlp_pipeline_bert = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            bert_embeddings,\n",
        "            embeddingsSentence,\n",
        "            embeddings_finisher])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLjbPOVPPEfu"
      },
      "source": [
        "nlp_model_bert = nlp_pipeline_bert.fit(df_train)\n",
        "\n",
        "processed_bert_train = nlp_model_bert.transform(df_train)\n",
        "\n",
        "processed_bert_train.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A96UC3oPD68"
      },
      "source": [
        "nlp_model_bert = nlp_pipeline_bert.fit(df_train)\n",
        "\n",
        "processed_bert_test = nlp_model_bert.transform(df_test)\n",
        "\n",
        "processed_bert_test.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcQqpkmoPDpn"
      },
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "processed_bert_train= processed_bert_train.withColumn(\"features\", explode(processed_bert_train.finished_sentence_embeddings))\n",
        "processed_bert_test= processed_bert_test.withColumn(\"features\", explode(processed_bert_test.finished_sentence_embeddings))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzt-lJCkPDh9"
      },
      "source": [
        "processed_bert_test.select('text','features','label').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmIycfsOPDSc"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "lrModel = lr.fit(processed_bert_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2WAnDhoTgmU"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(\"long\")\n",
        "def num_nonzeros(column):\n",
        "    return column.numNonzeros()\n",
        "\n",
        "processed_bert_test = processed_bert_test.where(num_nonzeros(\"features\") != 0)\n",
        "processed_bert_train = processed_bert_train.where(num_nonzeros(\"features\") != 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoR36gjTURkB"
      },
      "source": [
        "predictions_bert = lrModel.transform(processed_bert_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH4PIo43UR2W"
      },
      "source": [
        "predictions_bert.select(\"text\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBoI4Bd7USbk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCm2IblK0q30"
      },
      "source": [
        "> ### VI.  LogReg with Spark NLP Glove Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWKvpPeE1T8K"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer()\\\n",
        "      .setInputCols([\"token\"])\\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained()\\\n",
        "      .setInputCols([\"document\",'cleanTokens'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings()\\\n",
        "      .setInputCols([\"document\", \"embeddings\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "    \n",
        "embeddings_finisher = EmbeddingsFinisher()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCols([\"finished_sentence_embeddings\"])\\\n",
        "      .setOutputAsVector(True)\\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "explodeVectors = SQLTransformer(statement=\n",
        "      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"label\", outputCol = \"category\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX8fdqzU2gQZ"
      },
      "source": [
        "nlp_pipeline_w2v = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            embeddings_finisher,\n",
        "            explodeVectors])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fwQhE9f3gwW"
      },
      "source": [
        "\n",
        "nlp_model_w2v = nlp_pipeline_w2v.fit(df_train)\n",
        "\n",
        "processed_w2v_train = nlp_model_w2v.transform(df_train)\n",
        "\n",
        "processed_w2v_train.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzrbjQ3b4I6L"
      },
      "source": [
        "nlp_model_w2v = nlp_pipeline_w2v.fit(df_train)\n",
        "\n",
        "processed_w2v_test = nlp_model_w2v.transform(df_test)\n",
        "\n",
        "processed_w2v_test.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7kel6Im4qD_"
      },
      "source": [
        "processed_w2v_test.show(truncate=True, n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCyD_jqv5ZIN"
      },
      "source": [
        "processed_w2v_test.select('finished_sentence_embeddings').take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7FETE955Yxm"
      },
      "source": [
        "processed_w2v_test.select('text','features','label').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYIPlBBaFtdY"
      },
      "source": [
        "from pyspark.sql.functions import explode\n",
        "processed_w2v_train= processed_w2v_train.withColumn(\"features\", explode(processed_w2v_train.finished_sentence_embeddings))\n",
        "processed_w2v_test= processed_w2v_test.withColumn(\"features\", explode(processed_w2v_test.finished_sentence_embeddings))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11lABS_S5YWX"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "@udf(\"long\")\n",
        "def num_nonzeros(column):\n",
        "    return column.numNonzeros()\n",
        "\n",
        "processed_w2v_test = processed_w2v_test.where(num_nonzeros(\"features\") != 0)\n",
        "processed_w2v_train = processed_w2v_train.where(num_nonzeros(\"features\") != 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lFDvoNv-Ala"
      },
      "source": [
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
        "lrModel_w2v = lr.fit(processed_w2v_train)\n",
        "predictions_w2v = lrModel_w2v.transform(processed_w2v_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGZu0QP6-UaV"
      },
      "source": [
        "predictions_w2v.select(\"text\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F48SeyOmJC_s"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "\n",
        "evaluator.evaluate(predictions_w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_4DvlKVufMh"
      },
      "source": [
        "> ### VI. Random Forest with TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVorCxmZuqM8"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXoHYVkuuq17"
      },
      "source": [
        "rf = RandomForestClassifier(labelCol=\"label\",\\\n",
        "                            featuresCol=\"features\",\\\n",
        "                            numTrees = 100,\\\n",
        "                            maxDepth = 4,\\\n",
        "                            maxBins = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7aeFlc4urBv"
      },
      "source": [
        "rfModel = rf.fit(processed_tf_train)\n",
        "predictions_rf = rfModel.transform(processed_tf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybXXts_yurIF"
      },
      "source": [
        "predictions_rf.filter(predictions_rf['prediction'] == 0)\\\n",
        "    .select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
        "    .orderBy(\"probability\", ascending=False)\\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykCbone-urUT"
      },
      "source": [
        "predictions_rf.filter(predictions_rf['prediction'] == 1)\\\n",
        "    .select(\"text\",\"probability\",\"label\",\"prediction\")\\\n",
        "    .orderBy(\"probability\", ascending=False)\\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tQQzOrA0p7F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOiQV1pOY260"
      },
      "source": [
        "# Data Pre-processing (Training Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bIqe0mYudE7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwwHHc2NY261"
      },
      "source": [
        "**Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "FOG6jNQwY261"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='sentiment_words')\n",
        "tokenized_train = tokenizer.transform(df_train)\n",
        "tokenized_train.show(truncate=True, n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3VYqjdGY262"
      },
      "source": [
        "**Removing Stop Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "yfPta6VYY262"
      },
      "source": [
        "from pyspark.ml.feature import StopWordsRemover\n",
        "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='decisive_words')\n",
        "swr_free_train = swr.transform(tokenized_train)\n",
        "swr_free_train.show(truncate=True, n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov3WBZeHY263"
      },
      "source": [
        "**Hashing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXLQPARfY264"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "\n",
        "hashingTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"raw_features\")\n",
        "numeric_train = hashingTF.transform(swr_free_train).select('decisive_words','raw_features', 'label')\n",
        "numeric_train.show(truncate=True, n=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnWBWM2vY264"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arenGKopY265"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(labelCol='label', featuresCol='raw_features', maxIter = 5, regParam=.001)\n",
        "model_lr = logreg.fit(numeric_train)\n",
        "print('model_lr is trained')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV4X5EKPY266"
      },
      "source": [
        "tokenized_test = tokenizer.transform(df_test)\n",
        "swr_free_test = swr.transform(tokenized_test)\n",
        "numeric_test = hashingTF.transform(swr_free_test).select('decisive_words','raw_features', 'label')\n",
        "numeric_test.show(truncate=True, n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGuT1C-FY266"
      },
      "source": [
        "predict_logreg = model_lr.transform(numeric_test)\n",
        "predicted_logreg_df = predict_logreg.select(\n",
        "    \"decisive_words\", \"prediction\", \"label\")\n",
        "predicted_logreg_df = predicted_logreg_df.withColumn('prediction', predicted_logreg_df.prediction.cast(IntegerType()))\n",
        "predicted_logreg_df.show(truncate = True, n=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR4YA0KLY267"
      },
      "source": [
        "def confusion_matrix(df,prediction,label):\n",
        "    \"\"\"\n",
        "    Generates a manual confusion matrix in a pyspark data frame, which is assembled according to the classification prediction. \n",
        "    df = Data Frame with prediction and label values\n",
        "    prediction = string, column name of the prediction values\n",
        "    label = string, column name of the label values\n",
        "    \"\"\"\n",
        "    correctly_predicted = df.filter(df.prediction == df.label).count()\n",
        "    false_positive = df.filter((df.prediction == 1) & (df.label == 0)).count()\n",
        "    false_negative = df.filter((df.prediction == 0) & (df.label == 1)).count()\n",
        "    true_positive = df.filter((df.prediction == 1) & (df.label == 1)).count()\n",
        "    true_negative = df.filter((df.prediction == 0) & (df.label == 0)).count()\n",
        "    \n",
        "    accuracy = correctly_predicted/df.count()\n",
        "    precision = true_positive/(true_positive + false_positive)\n",
        "    recall = true_positive/(true_positive + false_negative)\n",
        "    f1_score = 2 * ((precision * recall)/(precision + recall))\n",
        "\n",
        "    \n",
        "    print(f'Correctly Predicted (True Positive): {correctly_predicted} which is %{correctly_predicted/df.count()}')\n",
        "    print(f'Type-I Error (False Positive): {false_positive} which is %{false_positive/df.count()}')\n",
        "    print(f'Type-II Error (False Negative): {false_negative} which is %{false_negative/df.count()}')\n",
        "    print(f'Accuracy: %{accuracy}')\n",
        "    print(f'Precision: %{precision}')\n",
        "    print(f'Sensitivity(Recall): %{recall}')\n",
        "    print(f'F1 Score: %{f1_score}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATwhwFa8Y268"
      },
      "source": [
        "confusion_matrix(predicted_logreg_df, 'prediction','label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFYSSoMGY268"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yec9fqFKY269"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhgWK6G1Y26-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "id": "nWP1oz0zY26-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFG4KEr7Y26_"
      },
      "source": [
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9R5fhAxY27A"
      },
      "source": [
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8frItt2Y27A"
      },
      "source": [
        "rf = RandomForestClassifier(featuresCol = 'raw_features', labelCol = 'label')\n",
        "model_rf = rf.fit(numeric_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I5xRl7jY27B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yBrhzMfY27B"
      },
      "source": [
        "predict_rf = model_rf.transform(numeric_test)\n",
        "predicted_rf_df = predict_rf.select(\n",
        "    \"decisive_words\", \"prediction\", \"label\")\n",
        "predicted_rf_df = predicted_rf_df.withColumn('prediction', predicted_rf_df.prediction.cast(IntegerType()))\n",
        "predicted_rf_df.show(truncate = True, n=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggp4RR-5Y27C"
      },
      "source": [
        "predicted_rf_df.select('prediction').distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JffXyDvQY27D"
      },
      "source": [
        "confusion_matrix(predicted_rf_df, 'prediction','label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wsaW0LbY27E"
      },
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk9zQRTuY27E"
      },
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "## Fitting the model\n",
        "gbt = GBTClassifier(featuresCol = 'raw_features', labelCol = 'label', maxIter=10)\n",
        "model_gbt = gbt.fit(numeric_train)\n",
        "predicted_gbt = model_gbt.transform(numeric_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-gILOyrY27E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}